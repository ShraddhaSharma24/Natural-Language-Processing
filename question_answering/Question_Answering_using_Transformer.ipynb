{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPgVLOFQWpcZnRwG8bKsHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShraddhaSharma24/Natural-Language-Processing/blob/main/Question_Answering_using_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2w3PLe2TnoF0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QA_input=[{'question':'Why is conversion important?',\n",
        "          'context':'The option to convert models between FARM and transformers gives freedom to the users and let people switch easily between frameworks'},\n",
        "          {'question': 'How many programming languages does BLOOM support?',\n",
        "           'context':'BLOOM has 176 billion parameter and can generate text in 46 natural languages and 13 programmimg languages'}]"
      ],
      "metadata": {
        "id": "O_wlpb7roYAX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='deepset/roberta-base-squad2'\n"
      ],
      "metadata": {
        "id": "Xvr_M8wPvyaZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "g_LG239QwDBL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs0=tokenizer(QA_input[0]['question'],QA_input[0]['context'], return_tensors=\"pt\")\n",
        "output0=model(**inputs0)"
      ],
      "metadata": {
        "id": "mrmrznCAwj3K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EhNRtuzxNU6",
        "outputId": "b4af9318-7a6e-4dc5-fd3c-ba8fdec27d2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 1.7988, -7.3414, -8.5327, -8.3804, -8.4340, -9.2008, -3.0561, -7.4473,\n",
              "          0.7429, -0.8738, -3.2420, -2.7514, -3.6754, -4.9777, -5.3764, -7.4642,\n",
              "         -8.0218, -4.9106, -7.1374,  2.6252,  2.4262, -4.7439, -3.0135, -2.0931,\n",
              "         -3.6996,  0.4473, -5.1507, -2.1835, -4.2506, -5.3376, -4.0082, -3.0559]],\n",
              "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 2.3216, -7.9214, -8.5093, -8.2553, -7.7435, -7.0162,  1.9421, -4.8220,\n",
              "         -6.4433, -4.9460, -7.4925, -6.9475, -4.5191, -7.7907, -7.7397, -4.0800,\n",
              "         -8.0047, -6.5083, -2.0877, -3.9496,  0.8458, -3.5622, -4.8077,  3.2349,\n",
              "         -3.2815, -5.2688, -3.9324, -4.4810, -0.8880, -3.7088,  2.3121,  1.9421]],\n",
              "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1=tokenizer(QA_input[1]['question'],QA_input[1]['context'], return_tensors=\"pt\")\n",
        "output1=model(**inputs1)"
      ],
      "metadata": {
        "id": "wEfxRoBIxY0O"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_start_idx=torch.argmax(output0.start_logits)\n",
        "answer_end_idx=torch.argmax(output0.end_logits)"
      ],
      "metadata": {
        "id": "F7XrR1T8x8QE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_tokens=inputs0.input_ids[0,answer_start_idx:answer_end_idx+1]\n",
        "answer=tokenizer.decode(answer_tokens)\n",
        "print(\"ques: {}\\nanswer: {}\".format(QA_input[0]['question'],answer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5i6VwcfygPQ",
        "outputId": "625e803c-e3ae-47e4-bb38-9813662e5b9d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ques: Why is conversion important?\n",
            "answer:  gives freedom to the users\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pipeline"
      ],
      "metadata": {
        "id": "k4TtB-0k9PHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa=pipeline('question-answering', model=model_name, tokenizer=model_name)"
      ],
      "metadata": {
        "id": "RZbtkUaa7x5j",
        "outputId": "1fcb334e-3cdd-482f-c5ed-64585182f5ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_0=qa(QA_input[0]['question'], QA_input[0]['context'])\n",
        "print(output_0)"
      ],
      "metadata": {
        "id": "W1mMOYKo9f72",
        "outputId": "c5975a64-7583-4a8a-f2b3-2cea2ee61229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.20120589435100555, 'start': 59, 'end': 85, 'answer': 'gives freedom to the users'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_1=qa(QA_input[1]['question'], QA_input[1]['context'])\n",
        "print(output_1)\n"
      ],
      "metadata": {
        "id": "jyhzf7fg97Dl",
        "outputId": "b96d0963-cee4-49ed-d78b-2f2159fb815c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.550687849521637, 'start': 82, 'end': 84, 'answer': '13'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8vGnBtU-LjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}